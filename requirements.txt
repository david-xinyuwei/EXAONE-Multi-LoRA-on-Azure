# vLLM Multi-LoRA Serving for EXAONE
# Tested on: Python 3.11, CUDA 12.x, NVIDIA H100 NVL 95.8GB

# ── Serving (vLLM Multi-LoRA) ──
vllm==0.15.1
# vLLM 0.15.1 installs its own compatible versions:
#   transformers==4.57.6, torch==2.9.1

# ── LoRA Training (SFT) ──
# Note: EXAONE custom code requires transformers>=5.1 for training.
# Temporarily install for training, then downgrade for vLLM serving:
#   pip install transformers==5.1.0  (train)
#   pip install transformers==4.57.6 (serve)
peft>=0.15.0
datasets
accelerate

# ── Training Data Generation ──
openai>=1.0.0
